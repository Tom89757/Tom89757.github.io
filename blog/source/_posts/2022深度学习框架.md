---
title: 2022深度学习框架
date: 2022-05-08 18:54:36
categories:
- 考试
tags:
- 深度学习框架
---

本文记录以下2022年深度学习框架考试答案：

<!--more-->

### 单选题

1. （layers）模块提供了一组高级神经网络层

2. 假设需要改变参数来最小化代价函数（cost function），可以使用下列哪项技术？

   > 穷举搜索、随机搜索、Bayesian优化（以上任意一种）

3. 梯度下降算法的正确步骤是什么？

   1. 初始化随机权重和偏差
   2. 把输入传输网络，得到输出值
   3. 计算预测值和真实值之间的误差
   4. 对每一个产生误差的神经元，改变响应的（权重值）以减小误差
   5. 迭代更新，直到找到最佳权重

4. （TensorFlow）具有对多种语言的 API 支持，例如 Matlab 和 C++。研究人员一直在努力使它变得更好。还引入了一个 javascript 库 tensorflow.js，用于训练和部署机器学习模型。

5. 防止（过拟合）本质上来说就是添加先验。

### 多选题

1. TensorBoard 当前支持哪些可视化技术？

   > 图像、标量、音频、图形

2. TensorFlow 的主要优点包括以下哪些？

   > 定制和开源、平台灵活性、对线程/异步计算/队列具有高级支持

3. 以下哪些属于目标检测的四大任务？

   > 语义分割、目标分类、实例分割（还有目标定位）

4. 以下哪个是属于激活函数？

   > sigmoid、tanh、relu

5. CNN 结构特点包括哪些？

   > 局部连接、权值共享、池化操作

### 填空题

1. （TensorBoard）是一套可视化工具，用于检查和理解 TensorFlow 运行和图形。

2. TensorFlow 使用（张量）表示数据，（变量）维护状态。
3. TensorFlow 构架的三个工作组件是：
   - 预处理数据
   - 建立模型训练
   - 评估模型

4. 例举三个经典的卷积神经网络：AlexNet、DenseNet、ResNet、GoogleNet、VGG
5. 增加训练轮次，减少正则参数（减小高偏差），增加网络复杂度，是为了解决（欠拟合）现象。

### 判断题

1. 在 TensorFlow 及其开发方面，Python 是其主要语言。它是 TensorFlow 支持的第一种也是最易识别的语言，并且仍然支持大多数功能。TensorFlow 的功能似乎最初是在 Python 种定义的，后来又转移到了 C++。（正确）
2. TensorFlow 不提供对 OpenCL 的支持。（正确）
3. TensorFlow 来源是识别并提供服务的模块类型。每个源提供零个或多个可服务流。每个可服务版本都提供了一个加载程序。使其可以访问，以便可以加载。（正确）
4. TensorFlow 最初由 Google Brain 团队的研究人员和工程师创建，并于 2015 年成为开源。（正确）
5. 在 TensorFlow 中， 可以在同一个会话中创建两个计算图。（错误）

### 实训题

1. 全连接层和激活函数的反向传播的实现

   1）实现全连接层的反向传播

   ```python
   import numpy as np
   
   class FullyConnected:
       def __init__(self, W, b):
           r'''
           全连接层的初始化。
           Parameter:
           - W: numpy.array, (D_in, D_out)
           - b: numpy.array, (D_out)
           '''
           self.W = W
           self.b = b
           
           self.x = None
           self.original_x_shape = None
           
       def forward(self, x):
           r'''
           全连接层的前向传播
           Parameter:
           - x: numpy.array, (B, d1, d2, ..., dk)
           Return:
           - y: numpy.array, (B, M)
           '''
           """Begin"""
           y = np.dot(x, self.W) + self.b
           return y
       	"""End"""
       def backward(self, dout):
           r'''
           全连接层的反向传播
           Parameter:
           - dout: numpy.array, (B, M)
           Return:
           - dx: numpy.array, (B, d1, d2, ..., dk) 与self.original_x_shape形状相同
           另外，还需计算以下结果：
           - self.dW: numpy.array, (N, M)与self.W形状相同
           - self.db: numpy.array, (M,)      
           '''
           """Begin"""
           dx = np.dot(dout, self.W.T)
           self.dW = np.dot(self.x.T, dout)
           self.db = np.sum(dout, axis=0)
           return dx
       	"""End"""
           
   ```

   2）实现常用激活函数的反向传播

   ```python
   import numpy as np
   
   class Sigmoid:
       def __init__(self):
           self.out = None
       
       def forward(self, x):
           r'''
           Sigmoid激活函数的前向传播。
           
           Parameter:
           - x:　numpy.array, (B, d1, d2, ..., dk)
           
           Return :
           - y: numpy.array, (B, d1, d2, ..., dk)
           '''
           """Begin"""
           y = 1 / (1 + np.exp(-x))
           return y
       	"""End"""
       def backward(self, dout):
           r'''
           sigmoid的反向传播
           Parameter:
           - dout: numpy.array, (B, d1, d2, ..., dk)
           Return:
           - dx: numpy.array, (B, d1, d2, ..., dk)
           '''
           """Begin"""
           dx = dout * (1.0 - self.out) * self.out
           return dx
           """End"""
           
   class ReLU:
   	def __init__(self):
           self.mask = None
       
   	def forward(self, x):
           r'''
           ReLU激活函数的前向传播
           
           Parameter:
           - x: numpy.array, (B, d1, d2, ..., dk)
           
           Return:
           - y: numpy.array, (B, d1, d2, ..., dk)
           '''
           """Begin"""
           self.mask = (x<=0)
           out = x.copy()
           out[self.mask] = 0
           return out
       	"""End"""
   	def backward(self, dout):
           r'''
           relu的反向传播
           Parameter:
           - dout: numpy.array, (B, d1, d2, ..., dk)
           Return:
           - dx: numpy.array, (B, d1, d2, ..., dk)
           '''
   		"""Begin"""
           dout[self.mask]= 0
           dx = dout
           return dx
       	"""End"""
   ```

   

2. TensorFlow 入门——运算

   1）TensorFlow 基本运算

   ```python
   import tensorflow as tf
   import os
   
   os.environ["TF_CPP_MIN_LOG_LEVEL"]='3'
   
   def simple_func(a, b, c, d):
       """
       返回值：
       result：一个标量值
       """
       # 请在此添加代码
       """Begin"""
       ta = tf.constant(a) # ta表示a的tensor形式
       tb = tf.constant(b)
       tc = tf.constant(c)
       td = tf.constant(d)
       result = tf.multiply(tf.add(ta, tb), tf.add(tc, td)).eval()
       """End"""
       
   a = int(input())
   b = int(input())
   c = int(input())
   d = int(input())
   
   init_op = tf.global_variables_initializer()
   
   with tf.Session() as sess:
       sess.run(init_op)
       print(simple_func(a,b,c,d))
   ```

   

3. TensorFlow 入门——构建神经网络

   1）神经元与激活函数

   ```python
   import tensorflow as tf
   # 模拟一个 M-P 神经元的工作原理
   # input_value是输入值，类型为一维的tf.constant
   # weight 是这个神经元的权重，类型为一维的tf.constant
   # threshold 是这个神经元的阈值，类型为零维的tf.constant
   # 返回值是一个浮点数
   def neuron(input_value, weight, threshold):
       # 请在此添加代码 完成本关任务
       """Begin"""
       out = tf.reduce_sum(input_value*weight)-threshold
       out = tf.sigmoid(out)
       return out.eval()
   	"""End"""
   ```

   2）神经元与激活函数——tanh方法

   ```python
   import tensorflow as tf
   # 模拟一个 M-P 神经元
   class neuron(object):
       # 构造函数
       # weight为本神经元的权重，类型为一维的tf.constant
       # threshold为本神经元的阈值，类型为零维的tf.constant
       def __init__(self, weight, threshold):
           # 请在此添加代码，完成本关任务
           """Begin"""
           self.weight = weight
           self.threshold = threshold
           """End"""
           
       # 计算函数
       # input_value 是输入值，类型为一维的tf.constant
       # 返回值是一个浮点数
       def computes(self, input_value):
           # 请在此添加代码
           """Begin"""
           self.input_value = input_value
           out = tf.reduce_sum(input_value * self.weight) - self.threshold
           out = tf.tanh(out)
           return out.eval()
       	"""End"""       
   ```

   3）构建简单的单隐层前馈神经网络

   ```python
   import tensorflow as tf
   # 模拟一个 M-P 神经元
   class neuron(object):
       # 构造函数
       # weight为本神经元的权重，类型为一维的tf.constant
       # threshold为本神经元的阈值，类型为零维的tf.constant
       def __init__(self, weight, threshold):
           # 请在此添加代码，完成本关任务
           """Begin"""
           self.weight = weight
           self.threshold = threshold
           """End"""
           
       # 计算函数
       # input_value 是输入值，类型为一维的tf.constant
       # 返回值是一个浮点数
       def computes(self, input_value):
           # 请在此添加代码
           """Begin"""
           self.input_value = input_value
           out = tf.reduce_sum(input_value * self.weight) - self.threshold
           out = tf.tanh(out)
           return out.eval()
       	"""End"""   
       
   # 模拟神经网络中的一层
   class Dense(object):
       # 构造函数
       # weights 为本层中每个神经元的权重，元素类型为一维的tf.constant，weights的类型为python列表
       # thresholds 为本层中每个神经元的权重，元素类型为零维的tf.constant，thresholds的类型为python列表
       def __init__(self, weights, thresholds):
           # 请在此添加代码
           """Begin"""
           size = len(weights)
           self.neurons = []
           for i in range(size):
               self.neurons.append(neuron(weights[i], thresholds[i]))
           """End"""
       
       # 计算函数
       # input_value 为输入值，类型为一维的tf.constant
       # 返回值为一个1维，长度为n的Tensor，n为本层中神经元的数量
       def computes(self, input_value):
           #请在此添加代码
           """Begin"""
           L = []
           size = len(self.neurons)
           for i in range(size):
               L.append(self.neurons[i].computes(input_value))
           return tf.constant(L)
       	"""End"""
   # 模拟一个简单的神经网络
   # input_value是这个神经网络的输入，类型为一维的tf.constant
   # wegihtsOfMiddle 是这个神经网络中间层每个神经元的权重， 元素类型为一维的tf.constant，wegihtsOfMiddle的类型是python的列表
   # thresholdsOfMiddle 是这个神经网络中间层每个神经元的阈值， 元素类型为零维的tf.constant，thresholdsOfMiddle的类型是python的列表
   # wegihtsOfOut 是这个神经网络输出层每个神经元的权重， 元素类型为一维的tf.constant，wegihtsOfOut 的类型是python的列表
   # thresholdsOfOut 是这个神经网络输出层每个神经元的阈值， 元素类型为零维的tf.constant，thresholdsOfOut 的类型是python的列表
   # 返回值是一个一维浮点数组 （注意不是Tensor），数组的长度为输出层神经元的数量
   def NetWork(input_value, weightsOfMiddle, thresholdsOfMiddle, weightsOfOut, thresholdsOfOut):
       # 请在此添加代码
       """Begin"""
       	middle = Dense(weightsOfMiddle, thresholdsOfMiddle)
           out = Dense(weightsOfOut, thresholdsOfOut)
           return out.computes(middle.computes(input_value)).eval()
       """End"""
   ```

   

















