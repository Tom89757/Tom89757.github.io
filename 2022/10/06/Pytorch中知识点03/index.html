<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.2.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="x5ktgciuUZaSdL_MVZTZbxB3KlpKTLWWRI5NuYoIlXo">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"tom89757.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.15.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="本文记录一下在调试模型过程中的一些 Pytorch 框架和 python 相关知识点。">
<meta property="og:type" content="article">
<meta property="og:title" content="Pytorch中知识点03">
<meta property="og:url" content="https://tom89757.github.io/2022/10/06/Pytorch%E4%B8%AD%E7%9F%A5%E8%AF%86%E7%82%B903/index.html">
<meta property="og:site_name" content="世界在我面前展开">
<meta property="og:description" content="本文记录一下在调试模型过程中的一些 Pytorch 框架和 python 相关知识点。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/Tom89757/ImageHost/main/hexo/20221011160635.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Tom89757/ImageHost/main/hexo/20221006184108.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Tom89757/ImageHost/main/hexo/20221010164417.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Tom89757/ImageHost/main/hexo/20221018162553.png">
<meta property="article:published_time" content="2022-10-06T09:06:19.000Z">
<meta property="article:modified_time" content="2023-07-04T13:55:52.815Z">
<meta property="article:author" content="幻光">
<meta property="article:tag" content="python">
<meta property="article:tag" content="Pytorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Tom89757/ImageHost/main/hexo/20221011160635.png">


<link rel="canonical" href="https://tom89757.github.io/2022/10/06/Pytorch%E4%B8%AD%E7%9F%A5%E8%AF%86%E7%82%B903/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://tom89757.github.io/2022/10/06/Pytorch%E4%B8%AD%E7%9F%A5%E8%AF%86%E7%82%B903/","path":"2022/10/06/Pytorch中知识点03/","title":"Pytorch中知识点03"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Pytorch中知识点03 | 世界在我面前展开</title>
  

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?a5a702eb0224989403c29d3c91b068f0"></script>







  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="世界在我面前展开" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">世界在我面前展开</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">死亡扑面而来 腐朽接踵而至</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">幻光</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">133</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">85</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Tom89757" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Tom89757" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml" rel="noopener me"><i class="rss fa-fw"></i>RSS</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdn.jsdelivr.net/npm/@creativecommons/vocabulary@2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://tom89757.github.io/2022/10/06/Pytorch%E4%B8%AD%E7%9F%A5%E8%AF%86%E7%82%B903/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="幻光">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="世界在我面前展开">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Pytorch中知识点03 | 世界在我面前展开">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Pytorch中知识点03
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-10-06 17:06:19" itemprop="dateCreated datePublished" datetime="2022-10-06T17:06:19+08:00">2022-10-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-07-04 21:55:52" itemprop="dateModified" datetime="2023-07-04T21:55:52+08:00">2023-07-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>14k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>13 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>本文记录一下在调试模型过程中的一些 Pytorch 框架和 python 相关知识点。</p>
<span id="more"></span>
<ol>
<li>报错：</li>
</ol>
<pre class="line-numbers language-none"><code class="language-none">TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect … This means that the trace might not generalize to other inputs!<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="https://raw.githubusercontent.com/Tom89757/ImageHost/main/hexo/20221011160635.png" alt="" /></p>
<p>解决方案：将对应位置条件语句删除</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># if c.size() != att.size():</span>
<span class="token comment">#     att = F.interpolate(att, c.size()[2:], mode='bilinear', align_corners=False)</span>
<span class="token comment"># 删除if语句</span>
att <span class="token operator">=</span> F<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span>att<span class="token punctuation">,</span> c<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">,</span> align_corners<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token comment"># if lf.size()[2:] != hf.size()[2:]:</span>
hf <span class="token operator">=</span> F<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span>hf<span class="token punctuation">,</span> size<span class="token operator">=</span>lf<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">,</span> align_corners<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<blockquote>
<p>参考资料：</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://discuss.pytorch.org/t/tracerwarning-converting-a-tensor-to-a-python-index-might-cause-the-trace-to-be-incorrect-this-means-that-the-trace-might-not-generalize-to-other-inputs/42282">TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect…This means that the trace might not generalize to other inputs!</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/onnx/onnx/issues/2836">TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can’t record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs! #2836</a></li>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/66746307/torch-jit-trace-tracerwarning-converting-a-tensor-to-a-python-boolean-might-c">Torch JIT Trace = TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect</a></li>
</ol>
</blockquote>
</br>
<p>2.报如下错误：<br />
<img src="https://raw.githubusercontent.com/Tom89757/ImageHost/main/hexo/20221006184108.png" alt="" /><br />
其原因在于数据集的大小除以batch_size余1，最后只包含单个数据的batch无法完成<code>batch_norm</code>操作。<br />
解决方案：更改batch_size。</p>
</br>
3.出现报错` Can't parse 'dsize'. Sequence item with index 0 has a wrong type`：
<p><img src="https://raw.githubusercontent.com/Tom89757/ImageHost/main/hexo/20221010164417.png" alt="" /></p>
<p>其原因为<code>(W,H)</code>中数据类型不对，应该将<code>torch.Tensor</code>转为<code>int</code>。由于<code>H</code>和<code>W</code>均为一维Tensor，可以通过以下代码实现：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">H<span class="token punctuation">,</span> W <span class="token operator">=</span> H<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> W<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<blockquote>
<p>参考资料：</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/47588682/how-to-cast-a-1-d-inttensor-to-int-in-pytorch">How to cast a 1-d IntTensor to int in Pytorch</a></li>
</ol>
</blockquote>
</br>
4.当通过`state_dict = model_zoo.load_url(url_map_[model_name]`在线下载预训练的模型权重文件时，出现`urllib.error.HTTPError: HTTP Error 503: Egress is over the account limit.`错误。
![](https://raw.githubusercontent.com/Tom89757/ImageHost/main/hexo/20221018162424.png)
<ul>
<li>原因：状态码为<code>503 Service Unavailable</code>，表示临时的服务器维护或者过载，服务器当前无法处理请求，这个情况是暂时的，会在一段时间后恢复（实际上过了好多天都没修复）</li>
<li>解决方案：因为调用<code>model_zoo.load_url()</code>时会打印出该权重文件的下载地址和保存路径，可以通过手动下载并放入该路径来解决该问题，如下图所示<br />
<img src="https://raw.githubusercontent.com/Tom89757/ImageHost/main/hexo/20221018162553.png" alt="" /></li>
</ul>
<blockquote>
<p>参考资料：</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://zh.m.wikipedia.org/zh/HTTP%E7%8A%B6%E6%80%81%E7%A0%81">HTTP状态码</a></li>
</ol>
</blockquote>
</br>
5.报错：
<pre class="line-numbers language-python" data-language="python"><code class="language-python">Cannot interpret <span class="token string">'&lt;attribute '</span>dtype<span class="token string">' of '</span>numpy<span class="token punctuation">.</span>generic<span class="token string">' objects>'</span> <span class="token keyword">as</span> a data <span class="token builtin">type</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
解决方法：更新pandas
> 参考资料：
> 1. [TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type · Issue #18355 · numpy/numpy · GitHub](https://github.com/numpy/numpy/issues/18355)
</br>
6.`loss.backward()`报错：`grad can be implicitly created only for scalar outputs`
解决方法：`loss.mean().backward()`。
> 参考资料：
> 1. [Loss.backward() raises error 'grad can be implicitly created only for scalar outputs' - autograd - PyTorch Forums](https://discuss.pytorch.org/t/loss-backward-raises-error-grad-can-be-implicitly-created-only-for-scalar-outputs/12152/2)
</br>
7. Pytorch创建随机张量和创建张量：
- 随机张量均匀分布
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
x2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
x3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
x4 <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2048</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
- 随机张量标准正态分布
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
- 全部为1：
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
- 全部为0：
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
> 参考资料：
> 1. [PyTorch 常用方法总结1：生成随机数Tensor的方法汇总（标准分布、正态分布……） - 知乎](https://zhuanlan.zhihu.com/p/31231210)
> 2. [torch.ones — PyTorch 1.13 documentation](https://pytorch.org/docs/stable/generated/torch.ones.html)
> 3. [torch.ones_like — PyTorch 1.13 documentation](https://pytorch.org/docs/stable/generated/torch.ones_like.html)
> 4. [torch.zeros — PyTorch 1.13 documentation](https://pytorch.org/docs/stable/generated/torch.zeros.html)
> 5. [torch.zeros_like — PyTorch 1.13 documentation](https://pytorch.org/docs/stable/generated/torch.zeros_like.html)
</br>
8.BCE Loss vs Cross Entropy：
<blockquote>
<p>参考资料：</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://discuss.pytorch.org/t/bce-loss-vs-cross-entropy/97437">BCE Loss vs Cross Entropy - vision - PyTorch Forums</a></li>
<li>[Learning Day 57/Practical 5: Loss function — CrossEntropyLoss vs BCELoss in Pytorch; Softmax vs sigmoid; Loss calculation | by De Jun Huang | dejunhuang | Medium](<a target="_blank" rel="noopener" href="https://medium.com/dejunhuang/learning-day-57-practical-5-loss-function-crossentropyloss-vs-bceloss-in-pytorch-softmax-vs-bd866c8a0d23#:~:text=Difference%20in%20purpose%20(in%20practice,probability%2C%20you%20should%20use%20BCE.&amp;text=We%20cannot%20use%20sigmoid%20for,CrossEntropyLoss%20as%20the%20loss%20function.)">https://medium.com/dejunhuang/learning-day-57-practical-5-loss-function-crossentropyloss-vs-bceloss-in-pytorch-softmax-vs-bd866c8a0d23#:~:text=Difference in purpose (in practice,probability%2C you should use BCE.&amp;text=We cannot use sigmoid for,CrossEntropyLoss as the loss function.)</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html">BCELoss — PyTorch 1.13 documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html">CrossEntropyLoss — PyTorch 1.13 documentation</a></li>
</ol>
</blockquote>
</br>
9.张量最大值和最小值：
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 最大</span>
x<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 最小</span>
x<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
</br>
10.维度扩充、复制和压缩：
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 原始tensor x</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">366</span><span class="token punctuation">,</span> <span class="token number">400</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># shape: 366, 400</span>
<span class="token comment"># 扩充维度</span>
x <span class="token operator">=</span> x<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># shape: 1, 366, 400</span>
<span class="token comment"># 复制通道</span>
x <span class="token operator">=</span> x<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># shape: 3, 366, 400</span>
<span class="token comment"># 压缩维度</span>
x <span class="token operator">=</span> x<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># shape: 3, 366, 400 不能压缩非1的维度</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">366</span><span class="token punctuation">,</span> <span class="token number">400</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> x<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># shape: 366, 400</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
> 参考资料：
> 1. [记录一个Tensor操作——扩充维度+复制 - 知乎](https://zhuanlan.zhihu.com/p/442263715)
</br>
11.在Module中的如下操作报如下错误：
<pre class="line-numbers language-python" data-language="python"><code class="language-python">gaussian_2D <span class="token operator">=</span> get_gaussian_kernel<span class="token punctuation">(</span>k_gaussian<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> sigma<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>gaussian_filter <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                                         out_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                                         kernel_size<span class="token operator">=</span>k_gaussian<span class="token punctuation">,</span>
                                         padding<span class="token operator">=</span>k_gaussian <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span>
                                         bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
self<span class="token punctuation">.</span>gaussian_filter<span class="token punctuation">.</span>weight<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>gaussian_2D<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-error" data-language="error"><code class="language-error">Leaf variable was used in an inplace operation<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
![](https://raw.githubusercontent.com/Tom89757/ImageHost/main/hexo/20230218224821.png)
解决方案：注释掉151行
> 参考资料：
> 1. [Leaf variable was used in an inplace operation - PyTorch Forums](https://discuss.pytorch.org/t/leaf-variable-was-used-in-an-inplace-operation/308)
</br>
12.在Module的batch上面迭代：
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
	B<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
	<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>B<span class="token punctuation">)</span><span class="token punctuation">:</span>
		xi <span class="token operator">=</span> x<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
		xi <span class="token operator">=</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>xi<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</br>
13.对多个Tensor进行join。有两种方式：
- `torch.cat((tens_1, tens_2, -, tens_n), dim=0, *, out=None)`：在相同的dimension上concatenate多个tensor：
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">320</span><span class="token punctuation">,</span><span class="token number">320</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># x1.shape: (1,3,320,320)</span>
x2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">320</span><span class="token punctuation">,</span><span class="token number">320</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># x2.shape: (1,3,320,320)</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>x1<span class="token punctuation">,</span>x2<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># x.shape: (2,3,320,320)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
- `torch.stack((tens_1, tens_2, -, tens_n), dim=0, *, out=None)`：在一个新的dimension上concatenate一个tensor序列，tensor需要为相同的尺寸：
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">320</span><span class="token punctuation">,</span><span class="token number">320</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># x1.shape: (1,3,320,320)</span>
x2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">320</span><span class="token punctuation">,</span><span class="token number">320</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># x2.shape: (1,3,320,320)</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">(</span>x1<span class="token punctuation">,</span> x2<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># x.shape: (2,1,3,320,320)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
> 参考资料：
> 1. [How to join tensors in Pytorch](https://www.geeksforgeeks.org/how-to-join-tensors-in-pytorch/)
> 2. [How to join tensors in Pytorch?](https://www.tutorialspoint.com/how-to-join-tensors-in-pytorch) 
</br>
14.Pytorch对tensor取指定维度的切片。
<pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">320</span><span class="token punctuation">,</span><span class="token number">320</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># (16,3,320,320)</span>
a1 <span class="token operator">=</span> a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># (3,320,320)</span>
a2 <span class="token operator">=</span> a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token comment"># (1,3,320,320)</span>
a3 <span class="token operator">=</span> a<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># (1,3,320,320)</span>

b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># (1, 1, 320, 320)</span>
b1 <span class="token operator">=</span> b<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># (1, 320, 320)</span>
b2 <span class="token operator">=</span> b<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># (320, 320)</span>
b3 <span class="token operator">=</span> b<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># (1, 1, 320, 320)</span>

c <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># (16, 2, 320, 320)</span>
c1 <span class="token operator">=</span> c<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment"># (16, 1, 320, 320)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
> 参考资料：
> 1. [python - Tensorflow: How to slice tensor with number of dimension not changed? - Stack Overflow](https://stackoverflow.com/questions/51670073/tensorflow-how-to-slice-tensor-with-number-of-dimension-not-changed)
</br>
15.报错`RuntimeError: Function 'SqrtBackward0' returned nan values in its 0th output.`
解决方案：
<pre class="line-numbers language-python" data-language="python"><code class="language-python">grad_mag <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>grad_x_r<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> grad_y_r<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token comment"># 添加1e-8项</span>
grad_mag <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>grad_x_r<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> grad_y_r<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> <span class="token number">1e-8</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
> 参考资料：
> 1. [RuntimeError: Function 'SqrtBackward' returned nan values in its 0th output - autograd - PyTorch Forums](https://discuss.pytorch.org/t/runtimeerror-function-sqrtbackward-returned-nan-values-in-its-0th-output/48702/5)
</br>
16.报错`ImportError: cannot import name 'container_abcs' from 'torch._six'`。
原因：torch版本问题，本人版本为`1.10`。
解决方案：
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>_six <span class="token keyword">import</span> container_abcs
<span class="token comment"># 改为</span>
<span class="token keyword">import</span> collections<span class="token punctuation">.</span>abc <span class="token keyword">as</span> container_abcs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
> 参考资料：
> 1. [Colab Notebook: Cannot import name 'container_abcs' from 'torch._six'](https://stackoverflow.com/questions/70193443/colab-notebook-cannot-import-name-container-abcs-from-torch-six)
</br>
17.高效的tensor张量矩阵阈值过滤操作：
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> x
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.3552</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.3825</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8297</span><span class="token punctuation">,</span>  <span class="token number">0.3477</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.2035</span><span class="token punctuation">,</span>  <span class="token number">1.2252</span><span class="token punctuation">,</span>  <span class="token number">0.5002</span><span class="token punctuation">,</span>  <span class="token number">0.6248</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span> <span class="token number">0.1307</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.0608</span><span class="token punctuation">,</span>  <span class="token number">0.1244</span><span class="token punctuation">,</span>  <span class="token number">2.0139</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> mask <span class="token operator">=</span> x<span class="token punctuation">.</span>ge<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> mask
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>masked_select<span class="token punctuation">(</span>x<span class="token punctuation">,</span> mask<span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.2252</span><span class="token punctuation">,</span>  <span class="token number">0.5002</span><span class="token punctuation">,</span>  <span class="token number">0.6248</span><span class="token punctuation">,</span>  <span class="token number">2.0139</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
`torch.masked_select(x, mask)`和`x[mask]`作用相似，可能的差别见参考资料3。但二者返回的tensor均为一维张量，而不是和输入的x和mask相同的shape。
若想保持原始tensor的尺寸，可以进行如下操作：
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
mask<span class="token punctuation">[</span>x<span class="token operator">></span><span class="token number">0.5</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
result <span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> mask<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
> 参考资料：
> 1. [torch.masked_select — PyTorch 1.13 documentation](https://pytorch.org/docs/stable/generated/torch.masked_select.html)
> 2. [PyTorch中的masked_select选择函数 - 知乎](https://zhuanlan.zhihu.com/p/348035584)
> 3. [Please add "dim" feature for function "torch.masked_select" · Issue #48830 · pytorch/pytorch · GitHub](https://github.com/pytorch/pytorch/issues/48830)
</br>
18.PyTorch中的矩阵乘法操作：
点乘：矩阵逐个元素（element-wise）乘法
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> cv2
mask <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">'./mask.png'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>mask<span class="token punctuation">)</span>

edge <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">'./edge.png'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
edge <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>edge<span class="token punctuation">)</span>

mask1 <span class="token operator">=</span> mask <span class="token operator">/</span> <span class="token number">255.0</span>

mask_region <span class="token operator">=</span> mask1<span class="token punctuation">.</span>ge<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>
mask_final <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>edge<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
mask_final<span class="token punctuation">[</span>mask_region<span class="token operator">==</span><span class="token boolean">True</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
mask_final<span class="token punctuation">[</span>mask_region<span class="token operator">==</span><span class="token boolean">False</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>

edge1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>edge<span class="token punctuation">,</span> mask_final<span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
> 参考资料：
> 1. [随笔1: PyTorch中矩阵乘法总结 - 知乎](https://zhuanlan.zhihu.com/p/100069938)
> 2. [torch.Tensor的4种乘法_torch tensor 相乘_da_kao_la的博客-CSDN博客](https://blog.csdn.net/da_kao_la/article/details/87484403)
</br>
19.报错`RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! when resuming training`
> 参考资料：
> 1. [python - RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! when resuming training - Stack Overflow](https://stackoverflow.com/questions/66091226/runtimeerror-expected-all-tensors-to-be-on-the-same-device-but-found-at-least)
</br>
20.报错`Could not load dynamic library 'libnvinfer_plugin.so.7`。
解决方案：建立从`libvinfer`版本7到版本8的symbolic link
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># the follwoing path will be different for you - depending on your install method</span>
$ cd env<span class="token operator">/</span>lib<span class="token operator">/</span>python3<span class="token punctuation">.</span><span class="token number">10</span><span class="token operator">/</span>site<span class="token operator">-</span>packages<span class="token operator">/</span>tensorrt

<span class="token comment"># create symbolic links</span>
$ ln <span class="token operator">-</span>s libnvinfer_plugin<span class="token punctuation">.</span>so<span class="token punctuation">.</span><span class="token number">8</span> libnvinfer_plugin<span class="token punctuation">.</span>so<span class="token punctuation">.</span><span class="token number">7</span>
$ ln <span class="token operator">-</span>s libnvinfer<span class="token punctuation">.</span>so<span class="token punctuation">.</span><span class="token number">8</span> libnvinfer<span class="token punctuation">.</span>so<span class="token punctuation">.</span><span class="token number">7</span>

<span class="token comment"># add tensorrt to library path</span>
$ export LD_LIBRARY_PATH<span class="token operator">=</span>$LD_LIBRARY_PATH<span class="token punctuation">:</span><span class="token operator">~</span><span class="token operator">/</span>env<span class="token operator">/</span>lib<span class="token operator">/</span>python3<span class="token punctuation">.</span><span class="token number">10</span><span class="token operator">/</span>site<span class="token operator">-</span>packages<span class="token operator">/</span>tensorrt<span class="token operator">/</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
> 参考资料：
> 1. [tensorflow - Could not load dynamic library 'libnvinfer.so.7' - Stack Overflow](https://stackoverflow.com/questions/74956134/could-not-load-dynamic-library-libnvinfer-so-7)
</br>
21.报错`tensorflow.python.framework.errors_impl.PermissionDeniedError: : /storage/FT/pth/SCWSSOD/SCWSSOD28/events.out.tfevents.1678606756.node4.11263.0; Permission denied`
![](https://raw.githubusercontent.com/Tom89757/ImageHost/main/hexo/20230312170110.png)
解决方案：更改`/storage/FT/pth/SCWSSOD/SCWSSOD28`文件夹的权限
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">chmod</span> -R <span class="token number">777</span> /storage/FT/pth/SCWSSOD/SCWSSOD28<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
> 参考资料：
> 1. [tensorflow.python.framework.errors_impl.PermissionDeniedError: data · Issue #6393 · tensorflow/tensorflow · GitHub](https://github.com/tensorflow/tensorflow/issues/6393)
> 2. [tensorflow.python.framework.errors_impl.PermissionDeniedError: data · Issue #6393 · tensorflow/tensorflow · GitHub](https://github.com/tensorflow/tensorflow/issues/6393)
</br>
22.Pytorch保存中间权重作为checkpoint，并从中间权重加载权重开始继续训练：
1. 定义和初始化网络
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim

<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
2. 初始化优化器
<pre class="line-numbers language-python" data-language="python"><code class="language-python">optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
3. 保存checkpoint
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Additional information</span>
EPOCH <span class="token operator">=</span> <span class="token number">5</span>
PATH <span class="token operator">=</span> <span class="token string">"model.pt"</span>
LOSS <span class="token operator">=</span> <span class="token number">0.4</span>

torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>
            <span class="token string">'epoch'</span><span class="token punctuation">:</span> EPOCH<span class="token punctuation">,</span>
            <span class="token string">'model_state_dict'</span><span class="token punctuation">:</span> net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'optimizer_state_dict'</span><span class="token punctuation">:</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'loss'</span><span class="token punctuation">:</span> LOSS<span class="token punctuation">,</span>
            <span class="token punctuation">&#125;</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
4. 加载checkpoint
<pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>

checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'model_state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'optimizer_state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span>
loss <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span>

model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># - or -</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
> 参考资料：
> 1. [Saving and loading a general checkpoint in PyTorch — PyTorch Tutorials 1.13.1+cu117 documentation](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html)
</br>
23.将损失和张量加载到gpu中：
<pre class="line-numbers language-python" data-language="python"><code class="language-python">tree_loss <span class="token operator">=</span> TreeEnergyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
low_feats <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
high_feats <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
unlabeled_ROIs <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cuda'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
> 参考资料：
> 1. [Moving tensor to cuda - PyTorch Forums](https://discuss.pytorch.org/t/moving-tensor-to-cuda/39318)
</br>
24.报错`AttributeError: module 'distutils' has no attribute 'version'`。
问题：setuptools新版本中移除了某些属性
解决方案：对setuptools进行降级
<pre class="line-numbers language-python" data-language="python"><code class="language-python">pip install setuptools<span class="token operator">==</span><span class="token number">59.5</span><span class="token number">.0</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
> 参考资料：
> 1. [AttributeError: module 'distutils' has no attribute 'version' : with setuptools 59.6.0 · Issue #69894 · pytorch/pytorch · GitHub](https://github.com/pytorch/pytorch/issues/69894)
</br>
25.报错`Default process group has not been initialized, please make sure to call init_process_group`。
问题：网络中包含了`SyncBatchNorm`操作，该操作必须在两张卡上进行。
解决方案：将`SyncBatchNorm`改为`BatchNorm2d`。
<blockquote>
<p>参考资料：</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/detectron2/issues/3972">RuntimeError: Default process group has not been initialized, please make sure to call init_process_group. · Issue #3972 · facebookresearch/detectron2 · GitHub</a></li>
</ol>
</blockquote>
</br>
26.报错`Assertion 't>=0' && 't<n_classes' failed error`。
问题：通过以下方式初始化张量会导致出现`<0`的概率值，无法计算损失
<pre class="line-numbers language-python" data-language="python"><code class="language-python">images <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
masks <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
image<span class="token punctuation">,</span> mask <span class="token operator">=</span> images<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> masks<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
loss <span class="token operator">=</span> seg_loss<span class="token punctuation">(</span><span class="token punctuation">[</span>outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> mask<span class="token punctuation">)</span>
optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
解决方案：将`torch.randn()`改为`torch.ones()`。
<pre class="line-numbers language-python" data-language="python"><code class="language-python">images <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
masks <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cuda'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
> 参考资料：
> 1. [Assertion `t >= 0 && t < n_classes` failed error - vision - PyTorch Forums](https://discuss.pytorch.org/t/assertion-t-0-t-n-classes-failed-error/133794)
</br>
27.报错`TracerWarning: Encountering a list at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.`
问题：
<blockquote>
<p>参考资料：</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/70706389/pytorch-tensorboard-add-graph-dictionary-input-error">PyTorch TensorBoard add_graph() dictionary input error</a></li>
</ol>
</blockquote>
</br>
28.张量(tensor)所在设备和加载到cpu/gpu：
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">>></span> a<span class="token punctuation">.</span>device
device<span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span>
<span class="token operator">>></span> a <span class="token operator">=</span> a<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">>></span> a<span class="token punctuation">.</span>device
device<span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'cuda'</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token operator">>></span> a <span class="token operator">=</span> a<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">>></span> a<span class="token punctuation">.</span>device
device<span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</br>
29.处理图片时报错`ValueError: the input array must have size along channel_axis, got (267, 400)`。
![](https://raw.githubusercontent.com/Tom89757/ImageHost/main/hexo/20230421182748.png)
<p>问题：在使用Skimage处理单通道图片时进行了多余的转换：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">MASK <span class="token operator">=</span> color<span class="token punctuation">.</span>rgb2gray<span class="token punctuation">(</span>MASK<span class="token punctuation">)</span>  <span class="token comment"># shape of [h, w]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>解决方案：将上述代码改为，</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>MASK<span class="token punctuation">.</span>shape<span class="token operator">==</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span> 
	MASK <span class="token operator">=</span> color<span class="token punctuation">.</span>rgb2gray<span class="token punctuation">(</span>MASK<span class="token punctuation">)</span>  <span class="token comment"># shape of [h, w]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<blockquote>
<p>参考资料：</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://github.com/BarCodeReader/SelfReformer/issues/2">/data/<strong>init</strong>.py 54 MASK = color.rgb2gray(MASK) · Issue #2 · BarCodeReader/SelfReformer · GitHub</a></li>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/70895576/skimage-rgb2gray-giving-errors-the-input-array-must-have-size-3-along">python - Skimage rgb2gray giving errors, the input array must have size 3 along - Stack Overflow</a></li>
</ol>
</blockquote>
</br>
20.在`test.py`中设置GPU编号无效，仍使用GPU0
<pre class="line-numbers language-python" data-language="python"><code class="language-python">GPU_ID<span class="token operator">=</span><span class="token number">1</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'CUDA_VISIBLE_DEVICES'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>GPU_ID<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
原因：在导入`kornia`时出现了问题
解决方案：将上述代码放在`test.py`最前面
<blockquote>
<p>参考资料：</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/issues/80876">[1.12] os.environ[“CUDA_VISIBLE_DEVICES”] has no effect · Issue #80876 · pytorch/pytorch · GitHub</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/kornia/kornia/issues/1951"><code>import kornia</code> break CUDA lazy init · Issue #1951 · kornia/kornia · GitHub</a></li>
</ol>
</blockquote>
</br>
21.报错`tensorflow.python.framework.errors_impl.PermissionDeniedError:`
<blockquote>
<p>参考资料：</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/41606854/tensorflow-permission-denied-error-location">python - TensorFlow Permission Denied Error /Location - Stack Overflow</a></li>
</ol>
</blockquote>
</br>
22.在`bgnet.py`中导入上一层目录中其它文件夹中的包：
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> sys
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'../utils'</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> show_info <span class="token keyword">import</span> <span class="token operator">*</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
目录结构如下：
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">+</span><span class="token operator">-</span><span class="token operator">-</span>bgnet
\<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>bgnet<span class="token punctuation">.</span>py
<span class="token operator">+</span><span class="token operator">-</span><span class="token operator">-</span>utils
\<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>show_info<span class="token punctuation">.</span>py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
</br>
报错`"conda\activate.py", line 1210, in main print(activator.execute(), end='') UnicodeEncodeError: 'gbk' codec can't encode charact`
问题：git bash作为终端时Python编码格式未设置为`utf-8`
解决方案：在`.bashrc/.zshrc/.bash_path`中添加环境变量：
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">export</span> <span class="token assign-left variable">PYTHONIOENCODING</span><span class="token operator">=</span>utf-8
<span class="token builtin class-name">export</span> <span class="token assign-left variable">PYTHONLEGACYWINDOWSSTDIO</span><span class="token operator">=</span>utf-8<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
> 参考资料：
> 1. [python 3.x - Conda: UnicodeEncodeError: 'charmap' codec can't encode character '\u2580' in position 644: character maps to undefined - Stack Overflow](https://stackoverflow.com/questions/59974715/conda-unicodeencodeerror-charmap-codec-cant-encode-character-u2580-in-po)
> 2. [Can not activate/deactivate conda environment due to cmder lambda character not handled in conda encoder/decoder · Issue #7445 · conda/conda · GitHub](https://github.com/conda/conda/issues/7445)
</br>
23.关闭`nvidia-smi`命令中运行在指定显卡上的进程：
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">nvidia-smi <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">'python'</span> <span class="token operator">|</span> <span class="token function">grep</span> <span class="token number">19398</span> <span class="token operator">|</span> <span class="token function">awk</span> <span class="token string">'&#123; print $5 &#125;'</span> <span class="token operator">|</span> <span class="token function">xargs</span> -n1 <span class="token function">kill</span> -9<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
> 参考资料：
> 1. [python - How to kill process on GPUs with PID in nvidia-smi using keyword? - Stack Overflow](https://stackoverflow.com/questions/50193538/how-to-kill-process-on-gpus-with-pid-in-nvidia-smi-using-keyword)

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>幻光
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://tom89757.github.io/2022/10/06/Pytorch%E4%B8%AD%E7%9F%A5%E8%AF%86%E7%82%B903/" title="Pytorch中知识点03">https://tom89757.github.io/2022/10/06/Pytorch中知识点03/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/python/" rel="tag"># python</a>
              <a href="/tags/Pytorch/" rel="tag"># Pytorch</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/10/03/Large-Projects/" rel="prev" title="Large Projects">
                  <i class="fa fa-chevron-left"></i> Large Projects
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/10/08/Markdown%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95/" rel="next" title="Markdown语法记录">
                  Markdown语法记录 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">幻光</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">390k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">5:55</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.1/dist/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha256-gMRN4/6qeELzO1wbFa8qQLU8kfuF2dnAPiUoI0ATjx8=" crossorigin="anonymous">


<script src="https://unpkg.com/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '480px',
  right: 'unset',
  left: '32px',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: false,
  label: '🌓',
  autoMatchOsTheme: false
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>

</body>
</html>
